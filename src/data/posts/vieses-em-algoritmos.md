---
title: Apoio a Timnit Gebru e ética em algoritmos, por Celeste Kidd
description: "Discurso de Celeste Kidd para o evento #AIDebate2, que aborda de frente uma das pautas mais importantes para a tecnologia"
featured: true
image: ~/assets/images/kidd.jpg
pubDate: "2020-12-24T11:06:00.000Z"
socialImage: "/features/timnit-gebru.jpg"
---

<p class="lead">A pesquisadora Celeste Kidd, postou <a href="https://twitter.com/celestekidd/status/1341936884767854593">uma thread sobre viéses em algoritmos e a recente demissão de Timnit Gebru</a> que farão parte de seu discurso de abertura no evento <a href="https://twitter.com/hashtag/AIDebate2">#AIDebate2</a>, resolvi traduzir livremente para trazer esse tema, que é um dos mais importantes que nós enquanto sociedade vamos enfrentar e já estamos lidando com muitas de suas consequências. Todo o discurso abaixo é de Celeste Kidd:</p>

>Meu laboratório [@BerkeleyPsych](https://twitter.com/BerkeleyPsych) estuda como humanos formam crenças e constrõem seu entendimento do mundo. Em particular, nos focamos em como humanos navegam os vastos mares de todas as possíveis informações eles podem acessar e entender a respeito do mundo.

>O que gostaria de enfatizar hoje é que algoritmos enviesados não são apenas problemáticos pelos danos diretos que causa, mas também pelos danos em cascata de como impacta as crenças humanas.

>Algoritmos enviesados são problemáticos pois são sistemas que fazem interface com as pessoas todos os dias, incorporados em nossas vidas. Estes sistemas dirigem as crenças humanas de formas destrutivas, e muitas vezes, irreparáveis.

>O que nossa pesquisa mais recente mostra:
> 1. Pessoas não aprendem muito aprofundamente sobre a maioria das coisas no mundo.
> 2. Pessoas necessitam formar crenças rapidamente em ordem para agir.
> 3. Uma vez que uma pessoa forma uma crença, mecanismos cognitivos os dissuadem de revisitar esses tópicos.

>Algoritmos que servem conteúdo de notícias e mídias sociais recomendam o conteúdo baseado na possibilidade de engajamento do usuário – desta forma, levando os usuários a [interagirem com conteúdo que demonstram crenças homogêneas (às vezes um tanto selvagens)](https://www.reuters.com/article/us-alphabet-google-research-focus-idUSKBN28X1CB).

>Isto é problemático quando os usuários procuram estas fontes para se informarem, para que coletem informação que eles usarão para formar suas crenças; Estes sistemas muito provavelmente irão entregar os usuários [crenças incorretas e fortes que – ainda que haja vários esforços – são difíceis de se corrigir](https://www.youtube.com/watch?v=MX5cqgUVkQE).

>Aqui vai outro exemplo: Ambos LinkedIn e Amazon foram [expostos empregando tecnologias que promoviam homens e filtrando mulheres qualificadas para candidaturas de trabalho](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G). Mas os danos vão além de apenas candidatas mulheres nesses focos em particular.

>Inteligência Artificial enviesada de recrutamento certamente impacta as crenças de recrutadores utilizando os sistemas. Se suas buscas não apresentam mulheres qualificadas, muito provavelmente irão concluir que mulheres qualificadas não existem – quando, na verdade, é apenas um viés no sistema de aplicação.

>Eu gostaria de encerrar dizer que é um tempo terrível nesse mommento para ética em Inteligência Artificial. A [demissão de Timnit Gebru do Google marca uma sombria mudança de rumo](https://www.nytimes.com/2020/12/03/technology/google-researcher-timnit-gebru.html).

>Mesmo após o [#MeToo](https://twitter.com/hashtag/MeToo) e os protestos [#BlackLivesMatter](https://twitter.com/hashtag/BlackLivesMatter?src=hashtag_click) de 2020, é claro que os [interesses privados não irão suportar diversidade, igualdade e inclusão](https://techcrunch.com/2020/12/03/googles-co-lead-of-ethical-ai-team-says-she-was-fired-for-sending-an-email/).

>Deveria nos horrorizar que o controle de algoritmos que determinam tanto de nossas vidas continuem nas mãos de um minoria homogênea e limitada.

>O que [Timnit Gebru](https://twitter.com/timnitGebru) enfrentou no time de IA do Google é a norma. É [ouvir a respeito que não é comum](https://www.technologyreview.com/2020/12/16/1014634/google-ai-ethics-lead-timnit-gebru-tells-story/).

>Também infelizmente é a norma que as pessoas que falem verdades inconvenientes para o poder sejam descartadas. Estas pessoas são silenciosamente descartadas por instituições como o Google, quando expostos, [fingem que pessoas como Timnit fez alguma coisa errada](https://dynamic.uoregon.edu/jjf/institutionalbetrayal/).

>Esta resposta manipula a crença de todos em pensar que pessoas não representadas são assim pois causam problemas, não por que as próprias instituições discriminam.

>Mas você deve ouvir [Timnit Gebru](https://twitter.com/timnitGebru) – e muitas outris e outros - sobre o que o ambiente no Google é. Jeff Dean deveria se sentir envergonhado.

>O resto de nós tem a responsabilidade de olhar para do que se trata, e insistir que isso tenha um fim.

### Meus comentários

Estou acompanhando a questão da Timnit Gebru e suas implicações e seu grande trabalho, mas considero estas palavras [Celeste Kidd](https://www.kiddlab.com/) mais embasadas e melhores do que eu conseguiria articular. Também entendo que o inglês pode ser uma barreira algumas vezes e acredito que ao menos traduzir já posso, ainda que modestamente, ajudar a amplificar sua voz e mensagem.

Celeste Kidd usa o termo "Algorithmic bias", que eu traduzi como "Algoritmos enviesados". Não sei qual o consenso de tradução para o português, se alguém souber, pode me corrigir :) Inicialmente estava usando viéses em algoritmos, mas passaria, no meu entendimento, a velha desculpa de que o algoritmo em si é neutro, e esse é um dos exemplos do que não é.

Indico a leitura da thread de [Real Abril](https://twitter.com/RealAbril) [sobre a demissão dela, também do Google](https://twitter.com/RealAbril/status/1341135819487100928). Ela foi a mais bem sucedida recrutadora de diversidade na empresa, com impressivos 30.000% no aumento de contratação de pessoas negras. O relato é chocante, por exemplo, sua superiora uma vez disse a ela que deveria tratar internamente a sua fala como uma deficiência – Real Abril cita que ela possui um acentuado sotaque de baltimore, o que eu descontextualizado da cultura americana a esse respeito só posso pressumir que seja associado a grupos de pessoas negras em particular. Por favor, me corrigam se estiver errado. A thread também já guanhou [cobertura na mídia e a resposta ao Business Insider](https://www.businessinsider.com/google-fired-employee-diversity-recruiter-baltimore-accent-was-disability-2020-12) foi um uma evasiva: "We don't agree with the way April describes her termination, but it's not appropriate for us to provide a commentary about her claims."

Em outra thread, [Veni Kunche](https://twitter.com/venikunche) repotou uma [situação em que o Google se mostrou interessado em um projeto dela de diversidade em tecnologia](https://twitter.com/venikunche/status/1341844516576358402), o [Diversity Tech](https://twitter.com/DiversifyTechCo) e depois acabou lançando uma cópia, sem qualquer crédito.

Uma outra mulher, [Jingle Kells](https://twitter.com/justkelly_ok), também negra, respondeu sobre [o papel do RH da Google](https://twitter.com/justkelly_ok/status/1342162867261497345) em que que relatou assédio sexual de um diretor e que o RH lhe disse que não havia nenhuma outra denúncia a respeito. Duas outras mulheres depois a confidenciaram a mesma situação.

Jeff Dean citado nominalmente, é quem chefia o departamento de IA, ele foi um dos personagens em uma extensa – e elogiosa – matéria da New Yorker em 2018 com o título ["The Friendship That Made Google Huge"](https://www.newyorker.com/magazine/2018/12/10/the-friendship-that-made-google-huge/amp?__twitter_impression=true) sobre sua parceria com Sanjay Ghemawat, ambos autores do influente paper [MapReduce: Simplified Data Processing on Large Clusters](https://research.google/pubs/pub62/). O [CEO do Google, Sundar Pichai](https://www.theverge.com/2020/12/9/22165983/google-ceo-sundar-pichai-apology-timnit-gebru-exit) pediu descuplas pela controvérsia, mas foi bem evasivo. Para Timnit foi uma ["não-desculpa" só para manter a reputação da empresa](https://www.businessinsider.com/timnit-gebru-google-ceo-sundar-pichai-non-apology-ai-researcher-2020-12).

Os dias de _don't be evil_ definitivamente ficaram para trás.